{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chalsai/Safaricom-Stock-with-Spark/blob/main/Week_10_Thur_Spark_DataFrames_Project_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN1y8WOL1mLB"
      },
      "source": [
        "Instructions\n",
        "\n",
        "\n",
        "As a Data professional, you need to perform an analysis by answering questions about\n",
        "some stock market data on Safaricom from the years 2012-2017.\n",
        "You will need to perform the following:\n",
        "\n",
        "\n",
        "Data Importation and Exploration\n",
        "\n",
        "\n",
        "\n",
        "● Start a spark session and load the stock file while inferring the data types.\n",
        "\n",
        "● Determine the column names\n",
        "\n",
        "● Make observations about the schema.\n",
        "\n",
        "● Show the first 5 rows\n",
        "\n",
        "● Use the describe method to learn about the data frame\n",
        "Data Preparation\n",
        "\n",
        "● Format all the data to 2 decimal places i.e. format_number()\n",
        "\n",
        "● Create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "High Price versus volume of stock traded for a day\n",
        "Data Analysis\n",
        "\n",
        "● What day had the Peak High in Price?\n",
        "\n",
        "● What is the mean of the Close column?\n",
        "\n",
        "● What is the max and min of the Volume column?\n",
        "\n",
        "● How many days was the Close lower than 60 dollars?\n",
        "\n",
        "● What percentage of the time was the High greater than 80 dollars?\n",
        "\n",
        "● What is the Pearson correlation between High and Volume?\n",
        "\n",
        "● What is the max High per year?\n",
        "\n",
        "● What is the average Close for each Calendar Month?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIBFsNjy1mLE"
      },
      "source": [
        "#### Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyspark\n",
        "# ---\n",
        "#\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-yCC6Lz15cV",
        "outputId": "f070e6c2-dee1-46f9-e97e-05563684eb57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 48 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 51.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=530f2566e8ec57feb9abe4e834cb3d10f60e7a51c0aa2daa9ba7ed711e244c6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BzjvXpBc1mLG"
      },
      "outputs": [],
      "source": [
        "# Next, we run a local spark session\n",
        "# ---\n",
        "#\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVroJgWc1mLI"
      },
      "source": [
        "#### Load the Safaricom Stock CSV File, have Spark infer the data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o8iE24Gy1mLI"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('saf_stock.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_xLlg5x1mLJ"
      },
      "source": [
        "#### What are the column names?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-CIXHxI1mLJ",
        "outputId": "03c28e6e-e308-491a-a3c8-c115847f9e54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHTKKqq1mLL"
      },
      "source": [
        "#### What does the Schema look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tBGqudy1mLL",
        "outputId": "17668d04-411c-4e37-fac7-86f0d8d32042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: timestamp (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v86kywGt1mLM"
      },
      "source": [
        "#### Print out the first 5 columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSANOuVZ1mLM",
        "outputId": "8ffcd63c-b06b-432f-fff1-52187dfbb4c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Date=datetime.datetime(2012, 1, 3, 0, 0), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n",
              " Row(Date=datetime.datetime(2012, 1, 4, 0, 0), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n",
              " Row(Date=datetime.datetime(2012, 1, 5, 0, 0), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n",
              " Row(Date=datetime.datetime(2012, 1, 6, 0, 0), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n",
              " Row(Date=datetime.datetime(2012, 1, 9, 0, 0), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlZPckdD1mLN"
      },
      "source": [
        "#### Use describe() to learn about the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt_2a7051mLN",
        "outputId": "99a25e24-80c9-4864-a6bc-e0c33b3f9dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDyG1UeX1mLN"
      },
      "source": [
        "#### There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TIhVyla1mLO",
        "outputId": "7d0119e1-0cda-45cf-c141-c71b5a18616a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
            "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
            "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
            "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n",
            "root\n",
            " |-- summary: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: string (nullable = true)\n",
            " |-- Volume: string (nullable = true)\n",
            " |-- Adj Close: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Describe\n",
        "desc = df.describe()\n",
        "desc.show()\n",
        "desc.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GKCDwGBP1mLO"
      },
      "outputs": [],
      "source": [
        "\n",
        " # import format_number\n",
        "from pyspark.sql.functions import format_number\n",
        "\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VsLlnUJ1mLO"
      },
      "outputs": [],
      "source": [
        " # Format all the data to 2 decimal places i.e. format_number()\n",
        "desc.select(desc.summary,\n",
        "                  format_number(desc.Open.cast('float'),2).alias('Open'),\n",
        "                  format_number(desc.High.cast('float'),2).alias('High'),\n",
        "                  format_number(desc.Low.cast('float'),2).alias('Low'),\n",
        "                  format_number(desc.Close.cast('float'),2).alias('Close'),\n",
        "                  format_number(desc.Volume.cast('int'), 1).alias('Volume'),\n",
        "                  format_number(desc['Adj Close'].cast('float'), 2).alias('AdjClose')).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBcUIXQe1mLP"
      },
      "source": [
        "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJqFhbBg1mLP",
        "outputId": "8cddb482-a827-45b6-b0a1-96a9ddf75b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            HV Ratio|\n",
            "+--------------------+\n",
            "|4.819714653321546E-6|\n",
            "|6.290848613094555E-6|\n",
            "|4.669412994783916E-6|\n",
            "|7.367338463826307E-6|\n",
            "|8.915604778943901E-6|\n",
            "|8.644477436914568E-6|\n",
            "|9.351828421515645E-6|\n",
            "| 8.29141562102703E-6|\n",
            "|7.712212102001476E-6|\n",
            "|7.071764823529412E-6|\n",
            "|1.015495466386981E-5|\n",
            "|6.576354146362592...|\n",
            "| 5.90145296180676E-6|\n",
            "|8.547679455011844E-6|\n",
            "|8.420709512685392E-6|\n",
            "|1.041448341728929...|\n",
            "|8.316075414862431E-6|\n",
            "|9.721183814992126E-6|\n",
            "|8.029436027707578E-6|\n",
            "|6.307432259386365E-6|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a new data frame with a column called HV Ratio\n",
        "hv = df.withColumn('HV Ratio', df['High']/df['Volume'])\n",
        "hv.select('HV Ratio').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIfA1Uss1mLQ"
      },
      "source": [
        "#### What day had the Peak High in Price?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUJjnb3u1mLQ",
        "outputId": "e9a0ed97-4380-43d0-e46f-00335bc7a73b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2015, 1, 13, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df.orderBy(df[\"High\"].desc()).head(1)[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Drq4AJC1mLQ"
      },
      "source": [
        "#### What is the mean of the Close column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfMPJcjB1mLR",
        "outputId": "2dfd5288-ec58-42df-b21f-a129ceaeee62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(avg(Close)=72.38844998012726)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df.select(['Close']).agg({'Close':'avg'}).collect()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8pGiTVl1mLR"
      },
      "source": [
        "#### What is the max and min of the Volume column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vH5aJuy1mLS"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import max, min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BptfaPff1mLS",
        "outputId": "9c4a016d-4646-497c-947b-84d7f6cb9f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+\n",
            "|max(Volume)|min(Volume)|\n",
            "+-----------+-----------+\n",
            "|   80898100|    2094900|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(max(\"Volume\"), min(\"Volume\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpUU-L9i1mLS"
      },
      "source": [
        "#### How many days was the Close lower than 60 dollars?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_UgltFL1mLS",
        "outputId": "5083a707-ba39-44c0-9234-d747d081ed14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.filter('Close < 60').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO3hvPZZ1mLT"
      },
      "source": [
        "#### What percentage of the time was the High greater than 80 dollars ?\n",
        "#### In other words, (Number of Days High>80)/(Total Days in the dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "WC9IA2qq1mLT",
        "outputId": "63103772-d550-4ba7-c1b8-7edaaab3cafe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9.141494435612083"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.filter('High>80').count()/df.select('High').count() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjniByLs1mLU"
      },
      "source": [
        "#### What is the Pearson correlation between High and Volume?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ImKJtt11mLU",
        "outputId": "fa9f8af8-cd70-4b7c-dd41-209c5680e930"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+\n",
            "| corr(Volume, High)|\n",
            "+-------------------+\n",
            "|-0.3384326061737161|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import corr\n",
        "df.select(corr('Volume', 'High')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sy2e_TA1mLV"
      },
      "source": [
        "#### What is the max High per year?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFpCGIlE1mLV",
        "outputId": "7e06e62e-24ca-44bb-dc4d-4a3afc928543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+---------+\n",
            "|Year|max(High)|\n",
            "+----+---------+\n",
            "|2015|90.970001|\n",
            "|2013|81.370003|\n",
            "|2014|88.089996|\n",
            "|2012|77.599998|\n",
            "|2016|75.190002|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import year\n",
        "df.withColumn(\"Year\", year(df[\"Date\"])).groupBy('Year').max().select('Year', \"max(High)\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxjxmRcK1mLV"
      },
      "source": [
        "#### What is the average Close for each Calendar Month?\n",
        "#### In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0Ar79w21mLW",
        "outputId": "d07dbcc5-4a15-4dc6-832d-7d200534fab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------------+\n",
            "|Month|       avg(Close)|\n",
            "+-----+-----------------+\n",
            "|    1|71.44801958415842|\n",
            "|    2|  71.306804443299|\n",
            "|    3|71.77794377570092|\n",
            "|    4|72.97361900952382|\n",
            "|    5|72.30971688679247|\n",
            "|    6| 72.4953774245283|\n",
            "|    7|74.43971943925233|\n",
            "|    8|73.02981855454546|\n",
            "|    9|72.18411785294116|\n",
            "|   10|71.57854545454543|\n",
            "|   11| 72.1110893069307|\n",
            "|   12|72.84792478301885|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import month\n",
        "df = df.withColumn(\"Month\", month('Date'))\n",
        "(df.select('Month', 'Close').groupBy('Month').avg().\n",
        "                    select('Month','avg(Close)')).orderBy('Month').show()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Week 10 Thur:Spark-DataFrames-Project-Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}